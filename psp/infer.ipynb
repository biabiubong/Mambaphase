{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed57f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sequence_embedding import SequenceToVectorModel\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch.cuda.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f263d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/public/home/kngll/Mamba_phase/data/esm2_t36_3B_UR50D1 /public/home/kngll/Mamba_phase/data/esm2_t36_3B_UR50D_mlm_finetuned.pth /public/home/kngll/Mamba_phase/model/weights2/model_epoch_10.pth /public/home/kngll/Mamba_phase/results/predictions.csv cuda:1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "BASE_DIR = os.path.dirname(BASE_DIR)\n",
    "\n",
    "\n",
    "\n",
    "esm_model_path = os.path.join(BASE_DIR, \"data\", \"esm2_t36_3B_UR50D1\")\n",
    "esm_weight_path = os.path.join(BASE_DIR, \"data\", \"esm2_t36_3B_UR50D_mlm_finetuned.pth\")\n",
    "cls_model_path = os.path.join(BASE_DIR, \"model\", \"weights2\", \"model_epoch_10.pth\")\n",
    "result_csv_path = os.path.join(BASE_DIR, \"results\", \"predictions.csv\")\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "AA_LIST = \"ACDEFGHIKLMNPQRSTVWYU\"\n",
    "\n",
    "print(esm_model_path, esm_weight_path, cls_model_path, result_csv_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edeea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams = {\n",
    "    'd_model': 256,\n",
    "    'd_inner': 128,    # 原64改为128（训练配置）\n",
    "    'n_ssm': 8,\n",
    "    'dt_rank': 8,      # 原1改为8（训练配置）\n",
    "    'n_layer': 1,\n",
    "    'dropout': 0.1,    # 原0.15改为0.1（训练配置）\n",
    "    'mlp_units': 1024,\n",
    "    'dropout_rate': 0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05475a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c50d90910a4201991dc7c02fd05537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4069834/3789001020.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  esm_model.load_state_dict(torch.load(esm_weight_path), strict=False)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共1条序列，计算esm表示...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4069834/3789001020.py:5: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    }
   ],
   "source": [
    "def infer_esm_rep(model, tokenizer, sequence, device):\n",
    "    encoded_inputs = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True)\n",
    "    encoded_inputs = {k: v.to(device) for k, v in encoded_inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            outputs = model(**encoded_inputs, output_hidden_states=True)\n",
    "    representations = outputs.hidden_states[-1]\n",
    "    last_hidden_state = representations[:, 0, :]\n",
    "    torch.cuda.empty_cache()\n",
    "    return last_hidden_state.squeeze(0).cpu()\n",
    "\n",
    "sequences = [\n",
    "    \"MNRYLNRQRLYNMEEERNKYRGVMEPMSRMTMDFQGRYMDSQGRMVDPRYYDHYGRMHDYDRYYGRSMFNQGHSMDSQRYGGWMDNPERYMDMSGYQMDMQGRWMDAQGRYNNPFSQMWHSRQGHYPGEEEMSHHSMYGRNMHYPYHSHSASRHFDSPERWMDMSGYQMDMQGRWMDNYGRYVNPFHHHMYGRNMFYPYGSHCNNRHMEHPERYMDMSGYQMDMQGRWMDTHGRHCNPLGQMWHNRHGYYPGHPHGRNMFQPERWMDMSSYQMDMQGRWMDNYGRYVNPFSHNYGRHMNYPGGHYNYHHGRYMNHPERQMDMSGYQMDMHGRWMDNQGRYIDNFDRNYYDYHMY\",\n",
    "    # 可添加更多序列\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(esm_model_path)\n",
    "esm_model = AutoModelForMaskedLM.from_pretrained(esm_model_path)\n",
    "esm_model.load_state_dict(torch.load(esm_weight_path), strict=False)\n",
    "esm_model = esm_model.to(device)\n",
    "\n",
    "print(f\"共{len(sequences)}条序列，计算esm表示...\")\n",
    "esm_reps = []\n",
    "for seq in sequences:\n",
    "    if len(seq) > 4000:\n",
    "        seq = seq[:4000]\n",
    "    try:\n",
    "        rep = infer_esm_rep(esm_model, tokenizer, seq, device)\n",
    "        esm_reps.append(rep)\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"OOM error! 忽略序列: \", seq[:10], \"...\")\n",
    "        torch.cuda.empty_cache()\n",
    "        esm_reps.append(torch.zeros(2560, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ad4192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备分类数据...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class PredictionDatasetV2(Dataset):\n",
    "    def __init__(self, sequences, esm_reps, amino_acid_to_index):\n",
    "        self.sequences = sequences\n",
    "        self.esm_reps = esm_reps\n",
    "        self.amino_acid_to_index = amino_acid_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        encoded_seq = torch.tensor([self.amino_acid_to_index.get(aa, 0) for aa in seq], dtype=torch.long)\n",
    "        esm_rep = self.esm_reps[idx]\n",
    "        return encoded_seq, esm_rep, seq\n",
    "def collate_fn_predict(batch):\n",
    "    seqs, esm_reps, origs = zip(*batch)\n",
    "    padded_seqs = pad_sequence(seqs, batch_first=True, padding_value=0)\n",
    "    esm_tensor = torch.stack([r if r.ndim==1 else r.squeeze(0) for r in esm_reps])\n",
    "    return padded_seqs, esm_tensor, origs\n",
    "amino_acid_to_index = {aa: idx for idx, aa in enumerate(AA_LIST)}\n",
    "print(\"准备分类数据...\")\n",
    "dataset = PredictionDatasetV2(sequences, esm_reps, amino_acid_to_index)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_predict, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299756b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载下游分类模型...\n"
     ]
    }
   ],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, sequence_model, mlp_units=512, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.sequence_model = sequence_model\n",
    "        \n",
    "        # 增强的MLP结构（4层）\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(2560, mlp_units),\n",
    "            nn.BatchNorm1d(mlp_units),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(mlp_units, mlp_units//2),\n",
    "            nn.BatchNorm1d(mlp_units//2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(mlp_units//2, mlp_units//4),\n",
    "            nn.BatchNorm1d(mlp_units//4),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # 分类器（2层）\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(mlp_units//4 + 256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, rdict_seqs):\n",
    "        embeddings = self.sequence_model(input_ids)\n",
    "        rdict_emb = self.mlp1(rdict_seqs)\n",
    "        combined = torch.cat([rdict_emb, embeddings], dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "def load_cls_model(cls_model_path):\n",
    "    sequence_model = SequenceToVectorModel(\n",
    "        vocab_size=len(AA_LIST),\n",
    "        d_model=best_hyperparams['d_model'],\n",
    "        d_inner=best_hyperparams['d_inner'],\n",
    "        n_ssm=best_hyperparams['n_ssm'],\n",
    "        dt_rank=best_hyperparams['dt_rank'],\n",
    "        n_layer=best_hyperparams['n_layer'],\n",
    "        dropout=best_hyperparams['dropout'],\n",
    "        output_dim=256\n",
    "    )\n",
    "    # 关键修改2：显式传递分类模型参数\n",
    "    model = ClassificationModel(\n",
    "        sequence_model,\n",
    "        mlp_units=best_hyperparams['mlp_units'],\n",
    "        dropout_rate=best_hyperparams['dropout_rate']\n",
    "    ).to(device)\n",
    "    # 关键修改3：设置weights_only=True并处理加载\n",
    "    state_dict = torch.load(cls_model_path, map_location=device, weights_only=True)\n",
    "    if any(k.startswith(\"module.\") for k in state_dict):\n",
    "        new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    else:\n",
    "        new_state_dict = state_dict\n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "print(\"加载下游分类模型...\")\n",
    "cls_model = load_cls_model(cls_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4cce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行预测...\n",
      "已写入: /public/home/kngll/Mamba_phase/results/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"进行预测...\")\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for seqs, esm_reps, origs in loader:\n",
    "        seqs = seqs.to(device)\n",
    "        esm_reps = esm_reps.to(device)\n",
    "        outputs = cls_model(seqs, esm_reps)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        for i in range(len(origs)):\n",
    "            results.append({\n",
    "                \"sequence\": origs[i],\n",
    "                \"prob_0\": probs[i][0].item(),\n",
    "                \"prob_1\": probs[i][1].item(),\n",
    "                \"prediction\": torch.argmax(probs[i]).item()\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "os.makedirs(os.path.dirname(result_csv_path), exist_ok=True)\n",
    "df.to_csv(result_csv_path, index=False)\n",
    "print(f\"已写入: {result_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepstabp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
