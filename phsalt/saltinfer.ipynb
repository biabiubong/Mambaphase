{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d231039c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa30d23bf92746baaeec99b4cc1ed006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4021258/2210844539.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  esm_model.load_state_dict(torch.load(esm_weight_path), strict=False)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共1条序列，计算esm表示...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4021258/2210844539.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# ------------------- 参数配置 --------------------\n",
    "esm_model_path=\"/public/home/kngll/llps/data/esm2_t36_3B_UR50D\"\n",
    "esm_weight_path=\"/public/home/kngll/Mambaphase/data/esm2_t36_3B_UR50D_mlm_finetuned.pth\"\n",
    "cls_model_path = \"/public/home/kngll/Mambaphase/model/saltweight/best_model.pth\"\n",
    "result_csv_path=\"/public/home/kngll/Mambaphase/results/predictions.csv\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ESM_WEIGHT_PATH = \"/public/home/kngll/Mambaphase/data/esm2_t36_3B_UR50D_mlm_finetuned.pth\"\n",
    "# ESM_MODEL_PATH = \"/public/home/kngll/llps/data/esm2_t36_3B_UR50D\"\n",
    "# CLS_MODEL_PATH = \"/public/home/kngll/Mambaphase/model/weights2/model_epoch_5.pth\"\n",
    "# RESULT_CSV_PATH = \"/public/home/kngll/Mambaphase/results/predictions.csv\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "AA_LIST = \"ACDEFGHIKLMNPQRSTVWYU\"\n",
    "\n",
    "\n",
    "amino_acid_to_index = {aa: idx for idx, aa in enumerate(AA_LIST)}\n",
    "\n",
    "def infer_esm_rep(model, tokenizer, sequence, device):\n",
    "    encoded_inputs = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True)\n",
    "    encoded_inputs = {k: v.to(device) for k, v in encoded_inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            outputs = model(**encoded_inputs, output_hidden_states=True)\n",
    "    representations = outputs.hidden_states[-1]\n",
    "    last_hidden_state = representations[:, 0, :]\n",
    "    torch.cuda.empty_cache()\n",
    "    return last_hidden_state.squeeze(0).cpu()\n",
    "\n",
    "sequences = [\n",
    "    \"GHGVYGHGVYGHGPYGHGPYGHGLYW\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(esm_model_path)\n",
    "esm_model = AutoModelForMaskedLM.from_pretrained(esm_model_path)\n",
    "esm_model.load_state_dict(torch.load(esm_weight_path), strict=False)\n",
    "esm_model = esm_model.to(DEVICE)\n",
    "\n",
    "print(f\"共{len(sequences)}条序列，计算esm表示...\")\n",
    "esm_reps = []\n",
    "for seq in sequences:\n",
    "    if len(seq) > 4000:\n",
    "        seq = seq[:4000]\n",
    "    try:\n",
    "        rep = infer_esm_rep(esm_model, tokenizer, seq, DEVICE)\n",
    "        esm_reps.append(rep)\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"OOM error! 忽略序列: \", seq[:10], \"...\")\n",
    "        torch.cuda.empty_cache()\n",
    "        esm_reps.append(torch.zeros(2560, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f041b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4021258/4283935562.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved predictions to /public/home/kngll/Mambaphase/results/predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# 已经有一个提取出来的特征列表“esm_reps ”，将/public/home/kngll/Mambaphase/model/phweight/best_model.pth模型导入。写出推断的代码，将结果保存到/public/home/kngll/Mambaphase/results/predictions.csv文件中。\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def predict_and_save(esm_reps, model_path, save_path):\n",
    "    # 设置设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 确保保存目录存在\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # 加载模型\n",
    "        model = MLPClassifier(2560,3).to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        # 转换输入数据\n",
    "        if not isinstance(esm_reps, list):\n",
    "            esm_reps = [esm_reps]\n",
    "            \n",
    "        # 预处理特征\n",
    "        processed_features = []\n",
    "        for feat in esm_reps:\n",
    "            if isinstance(feat, np.ndarray):\n",
    "                tensor_feat = torch.FloatTensor(feat)\n",
    "            elif isinstance(feat, torch.Tensor):\n",
    "                tensor_feat = feat.float()\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported feature type\")\n",
    "                \n",
    "            # 检查特征维度\n",
    "            if tensor_feat.dim() == 1:\n",
    "                tensor_feat = tensor_feat.unsqueeze(0)  # 添加batch维度\n",
    "            elif tensor_feat.dim() != 2:\n",
    "                raise ValueError(f\"Invalid feature dimension: {tensor_feat.shape}\")\n",
    "                \n",
    "            processed_features.append(tensor_feat)\n",
    "            \n",
    "        # 合并所有特征\n",
    "        batch_data = torch.cat(processed_features).to(device)\n",
    "        \n",
    "        # 执行预测\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_data)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # 转换为numpy\n",
    "        preds_np = preds.cpu().numpy()\n",
    "        probs_np = probs.cpu().numpy()\n",
    "        \n",
    "        # 创建结果DataFrame\n",
    "        results = pd.DataFrame({\n",
    "            \"prediction\": preds_np,\n",
    "            \"prob_low\": probs_np[:, 0],\n",
    "            \"prob_mid\": probs_np[:, 1],\n",
    "            \"prob_high\": probs_np[:, 2]\n",
    "        })\n",
    "        \n",
    "        # 保存结果\n",
    "        results.to_csv(save_path, index=False)\n",
    "        print(f\"Successfully saved predictions to {save_path}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设 esm_reps 是预先加载的特征列表\n",
    "    # 每个特征应为形状 (2560,) 的tensor或numpy数组\n",
    "    \n",
    "    # 模型路径\n",
    "    MODEL_PATH = \"/public/home/kngll/Mambaphase/model/saltweight/best_model.pth\"\n",
    "    \n",
    "    # 保存路径\n",
    "    SAVE_PATH = \"/public/home/kngll/Mambaphase/results/predictions.csv\"\n",
    "    \n",
    "    # 执行预测\n",
    "    predictions = predict_and_save(\n",
    "        esm_reps=esm_reps,\n",
    "        model_path=MODEL_PATH,\n",
    "        save_path=SAVE_PATH\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepstabp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
