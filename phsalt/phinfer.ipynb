{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7b97bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82529ee93c154b07a6fd239849d59ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3506264/1621199238.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  esm_model.load_state_dict(torch.load(esm_weight_path), strict=False)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共1条序列，计算esm表示...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3506264/1621199238.py:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# ------------------- 参数配置 --------------------\n",
    "esm_model_path=\"/public/home/kngll/llps/data/esm2_t36_3B_UR50D\"\n",
    "esm_weight_path=\"/public/home/kngll/Mambaphase/data/esm2_t36_3B_UR50D_mlm_finetuned.pth\"\n",
    "cls_model_path = \"/public/home/kngll/Mambaphase/model/weights2/model_epoch_5.pth\"\n",
    "result_csv_path=\"/public/home/kngll/Mambaphase/results/predictions.csv\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ESM_WEIGHT_PATH = \"/public/home/kngll/Mambaphase/data/esm2_t36_3B_UR50D_mlm_finetuned.pth\"\n",
    "# ESM_MODEL_PATH = \"/public/home/kngll/llps/data/esm2_t36_3B_UR50D\"\n",
    "# CLS_MODEL_PATH = \"/public/home/kngll/Mambaphase/model/weights2/model_epoch_5.pth\"\n",
    "# RESULT_CSV_PATH = \"/public/home/kngll/Mambaphase/results/predictions.csv\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "AA_LIST = \"ACDEFGHIKLMNPQRSTVWYU\"\n",
    "\n",
    "\n",
    "amino_acid_to_index = {aa: idx for idx, aa in enumerate(AA_LIST)}\n",
    "\n",
    "def infer_esm_rep(model, tokenizer, sequence, device):\n",
    "    encoded_inputs = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True)\n",
    "    encoded_inputs = {k: v.to(device) for k, v in encoded_inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            outputs = model(**encoded_inputs, output_hidden_states=True)\n",
    "    representations = outputs.hidden_states[-1]\n",
    "    last_hidden_state = representations[:, 0, :]\n",
    "    torch.cuda.empty_cache()\n",
    "    return last_hidden_state.squeeze(0).cpu()\n",
    "\n",
    "sequences = [\n",
    "    \" GHGVYGHGVYGHGPYGHGPYGHGLYW\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(esm_model_path)\n",
    "esm_model = AutoModelForMaskedLM.from_pretrained(esm_model_path)\n",
    "esm_model.load_state_dict(torch.load(esm_weight_path), strict=False)\n",
    "esm_model = esm_model.to(DEVICE)\n",
    "\n",
    "print(f\"共{len(sequences)}条序列，计算esm表示...\")\n",
    "esm_reps = []\n",
    "for seq in sequences:\n",
    "    if len(seq) > 4000:\n",
    "        seq = seq[:4000]\n",
    "    try:\n",
    "        rep = infer_esm_rep(esm_model, tokenizer, seq, DEVICE)\n",
    "        esm_reps.append(rep)\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        print(\"OOM error! 忽略序列: \", seq[:10], \"...\")\n",
    "        torch.cuda.empty_cache()\n",
    "        esm_reps.append(torch.zeros(2560, dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34663445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved predictions to /public/home/kngll/Mambaphase/results/predictions.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3506264/1446016910.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# 已经有一个提取出来的特征列表“esm_reps ”，将/public/home/kngll/Mambaphase/model/phweight/best_model.pth模型导入。写出推断的代码，将结果保存到/public/home/kngll/Mambaphase/results/predictions.csv文件中。\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "\n",
    "# 定义模型架构（必须与训练时相同）\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=2560, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def predict_and_save(esm_reps, model_path, save_path):\n",
    "    # 设置设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 确保保存目录存在\n",
    "    Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # 加载模型\n",
    "        model = MLPClassifier().to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        # 转换输入数据\n",
    "        if not isinstance(esm_reps, list):\n",
    "            esm_reps = [esm_reps]\n",
    "            \n",
    "        # 预处理特征\n",
    "        processed_features = []\n",
    "        for feat in esm_reps:\n",
    "            if isinstance(feat, np.ndarray):\n",
    "                tensor_feat = torch.FloatTensor(feat)\n",
    "            elif isinstance(feat, torch.Tensor):\n",
    "                tensor_feat = feat.float()\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported feature type\")\n",
    "                \n",
    "            # 检查特征维度\n",
    "            if tensor_feat.dim() == 1:\n",
    "                tensor_feat = tensor_feat.unsqueeze(0)  # 添加batch维度\n",
    "            elif tensor_feat.dim() != 2:\n",
    "                raise ValueError(f\"Invalid feature dimension: {tensor_feat.shape}\")\n",
    "                \n",
    "            processed_features.append(tensor_feat)\n",
    "            \n",
    "        # 合并所有特征\n",
    "        batch_data = torch.cat(processed_features).to(device)\n",
    "        \n",
    "        # 执行预测\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_data)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # 转换为numpy\n",
    "        preds_np = preds.cpu().numpy()\n",
    "        probs_np = probs.cpu().numpy()\n",
    "        \n",
    "        # 创建结果DataFrame\n",
    "        results = pd.DataFrame({\n",
    "            \"prediction\": preds_np,\n",
    "            \"prob_low\": probs_np[:, 0],\n",
    "            \"prob_mid\": probs_np[:, 1],\n",
    "            \"prob_high\": probs_np[:, 2]\n",
    "        })\n",
    "        \n",
    "        # 保存结果\n",
    "        results.to_csv(save_path, index=False)\n",
    "        print(f\"Successfully saved predictions to {save_path}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设 esm_reps 是预先加载的特征列表\n",
    "    # 每个特征应为形状 (2560,) 的tensor或numpy数组\n",
    "    \n",
    "    # 模型路径\n",
    "    MODEL_PATH = \"/public/home/kngll/Mambaphase/model/phweight/best_model.pth\"\n",
    "    \n",
    "    # 保存路径\n",
    "    SAVE_PATH = \"/public/home/kngll/Mambaphase/results/predictions.csv\"\n",
    "    \n",
    "    # 执行预测\n",
    "    predictions = predict_and_save(\n",
    "        esm_reps=esm_reps,\n",
    "        model_path=MODEL_PATH,\n",
    "        save_path=SAVE_PATH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2713a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理: high_ph\n",
      "正在处理: low_ph\n",
      "正在处理: neutral_ph\n",
      "\n",
      "数据集信息:\n",
      "- 总样本数: 355\n",
      "- 特征维度: 420\n",
      "- 类别分布: [ 39  30 286]\n",
      "\n",
      "分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     high_ph       0.25      0.12      0.17         8\n",
      "      low_ph       0.00      0.00      0.00         6\n",
      "  neutral_ph       0.82      0.96      0.89        57\n",
      "\n",
      "    accuracy                           0.79        71\n",
      "   macro avg       0.36      0.36      0.35        71\n",
      "weighted avg       0.69      0.79      0.73        71\n",
      "\n",
      "混淆矩阵:\n",
      "[[ 1  0  7]\n",
      " [ 1  0  5]\n",
      " [ 2  0 55]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/home/kngll/anaconda3/envs/deepstabp/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/public/home/kngll/anaconda3/envs/deepstabp/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/public/home/kngll/anaconda3/envs/deepstabp/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from propy import PyPro\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 配置参数\n",
    "DATA_DIR = \"/public/home/kngll/Mambaphase/data/ph\"  # 修改为实际路径\n",
    "CLASS_MAP = {\n",
    "    \"high_ph\": 0,\n",
    "    \"low_ph\": 1,\n",
    "    \"neutral_ph\": 2\n",
    "}\n",
    "VALID_AA = set(\"ACDEFGHIKLMNPQRSTVWY\")  # 标准氨基酸字符\n",
    "\n",
    "def validate_sequence(seq):\n",
    "    \"\"\"验证序列是否合法\"\"\"\n",
    "    return all(aa in VALID_AA for aa in seq.upper()) and len(seq) >= 5\n",
    "\n",
    "def extract_features(seq):\n",
    "    \"\"\"提取氨基酸组成（AAC）和二肽组成（DPC）特征\"\"\"\n",
    "    try:\n",
    "        descriptor = PyPro.GetProDes(seq)\n",
    "        # 氨基酸组成（20维）\n",
    "        aac = list(descriptor.GetAAComp().values())\n",
    "        # 二肽组成（400维）\n",
    "        dpc = list(descriptor.GetDPComp().values())\n",
    "        return aac + dpc\n",
    "    except Exception as e:\n",
    "        print(f\"特征提取失败: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"加载数据集并提取特征\"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for class_name, label in CLASS_MAP.items():\n",
    "        fasta_path = os.path.join(DATA_DIR, f\"{class_name}_sequences.fasta\")\n",
    "        if not os.path.exists(fasta_path):\n",
    "            raise FileNotFoundError(f\"文件不存在: {fasta_path}\")\n",
    "            \n",
    "        print(f\"正在处理: {class_name}\")\n",
    "        for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
    "            seq = str(record.seq).upper()\n",
    "            if not validate_sequence(seq):\n",
    "                continue\n",
    "                \n",
    "            features = extract_features(seq)\n",
    "            if features is not None:\n",
    "                X.append(features)\n",
    "                y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def main():\n",
    "    # 加载数据\n",
    "    X, y = load_dataset()\n",
    "    print(f\"\\n数据集信息:\")\n",
    "    print(f\"- 总样本数: {X.shape[0]}\")\n",
    "    print(f\"- 特征维度: {X.shape[1]}\")\n",
    "    print(f\"- 类别分布: {np.bincount(y)}\")\n",
    "\n",
    "    # 划分训练测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # 训练模型\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # 评估模型\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"\\n分类报告:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=CLASS_MAP.keys()))\n",
    "    print(\"混淆矩阵:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "737cdde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始中性序列数: 286 (已过滤无效序列)\n",
      "筛选后序列数: 40\n",
      "最大马氏距离: 1169.34\n",
      "最小选中距离: 123.20\n",
      "结果已保存至: /public/home/kngll/Mambaphase/data/ph/selected_neutral.fasta\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from propy import PyPro\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_features(seq):\n",
    "    \"\"\"提取氨基酸组成（AAC）和二肽组成（DPC）特征\"\"\"\n",
    "    try:\n",
    "        descriptor = PyPro.GetProDes(seq)\n",
    "        aac = list(descriptor.GetAAComp().values())   # 20维\n",
    "        dpc = list(descriptor.GetDPComp().values())    # 400维\n",
    "        return aac + dpc\n",
    "    except Exception as e:\n",
    "        print(f\"特征提取失败: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def load_features(fasta_path):\n",
    "    \"\"\"加载FASTA文件并提取有效特征及对应序列\"\"\"\n",
    "    features = []\n",
    "    valid_records = []\n",
    "    \n",
    "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
    "        seq = str(record.seq).upper()\n",
    "        # 过滤条件：长度≥10且只包含标准氨基酸\n",
    "        if len(seq) < 10 or not set(seq).issubset(\"ACDEFGHIKLMNPQRSTVWY\"):\n",
    "            continue\n",
    "            \n",
    "        feat = extract_features(seq)\n",
    "        if feat is not None:\n",
    "            features.append(feat)\n",
    "            valid_records.append(record)\n",
    "    \n",
    "    return np.array(features), valid_records\n",
    "\n",
    "# 加载所有数据\n",
    "high_path = \"/public/home/kngll/Mambaphase/data/ph/high_ph_sequences.fasta\"\n",
    "low_path = \"/public/home/kngll/Mambaphase/data/ph/low_ph_sequences.fasta\"\n",
    "neutral_path = \"/public/home/kngll/Mambaphase/data/ph/neutral_ph_sequences.fasta\"\n",
    "\n",
    "high_features, high_records = load_features(high_path)\n",
    "low_features, low_records = load_features(low_path)\n",
    "neutral_features, neutral_records = load_features(neutral_path)\n",
    "\n",
    "# 合并参考集（高+低pH）\n",
    "reference_features = np.concatenate([high_features, low_features])\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(reference_features)  # 仅用参考集计算标准化参数\n",
    "\n",
    "neutral_scaled = scaler.transform(neutral_features)\n",
    "reference_scaled = scaler.transform(reference_features)\n",
    "\n",
    "# 计算马氏距离\n",
    "def mahalanobis_distance(sample):\n",
    "    ref_mean = np.mean(reference_scaled, axis=0)\n",
    "    ref_cov = np.cov(reference_scaled, rowvar=False)\n",
    "    delta = sample - ref_mean\n",
    "    inv_cov = np.linalg.pinv(ref_cov)\n",
    "    return np.sqrt(delta.T @ inv_cov @ delta)\n",
    "\n",
    "distances = np.array([mahalanobis_distance(sample) for sample in neutral_scaled])\n",
    "\n",
    "# 筛选距离最大的前40条\n",
    "selected_indices = np.argsort(distances)[-40:][::-1]  # 降序排列取前40\n",
    "\n",
    "# 生成新FASTA文件\n",
    "output_path = \"/public/home/kngll/Mambaphase/data/ph/selected_neutral.fasta\"\n",
    "selected_records = [neutral_records[i] for i in selected_indices]\n",
    "\n",
    "with open(output_path, \"w\") as f:\n",
    "    SeqIO.write(selected_records, f, \"fasta\")\n",
    "\n",
    "# 打印验证信息\n",
    "print(f\"原始中性序列数: {len(neutral_records)} (已过滤无效序列)\")\n",
    "print(f\"筛选后序列数: {len(selected_records)}\")\n",
    "print(f\"最大马氏距离: {np.max(distances):.2f}\")\n",
    "print(f\"最小选中距离: {np.min(distances[selected_indices]):.2f}\")\n",
    "print(f\"结果已保存至: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da2eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepstabp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
